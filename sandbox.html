<!doctype html>
<html>
    <head>
        <script type="text/javascript">
const audioContext = new AudioContext()

function audioWorkletCode() {
    let t = 0
    console.log("AudioWorklet: start")

    class CustomProcessor extends AudioWorkletProcessor {
        constructor(options) {
            console.log("AudioWorklet: constructor")
            super()
            const blockSize = 1024
            this.currentBuffer = new Float32Array(blockSize)
            this.nextBuffer = new Float32Array(blockSize)
            this.index = 0

            this.port.onmessage = (e) => {
                // console.log("Audio Worklet <- Web Worker:", e.data)
                if (e.data.msg === "process") {
                    this.nextBuffer = e.data.output
                    this.nextBufferReady = true
                }
            }

            this.nextBufferReady = true
        }

        process(inputs, outputs, parameters) {
            // const out = outputs[0][0]
            // const numFrames = out.length
            // for (let i = 0; i < numFrames; i++) {
            //     out[i] = Math.sin(2*Math.PI*300*t)
            //     t += 1 / sampleRate
            // }
            // return true

            const output = outputs[0][0]
            if (this.index >= this.currentBuffer.length) {
                // Currently in underrun.
                console.log("Underrun!")
                output.fill(0)
            } else {
                output.set(this.currentBuffer.subarray(this.index, this.index + output.length))
            }
            // NOTE: This assumes currentBuffer.length is a multiple of output.length (128).
            this.index += output.length
            if (this.index >= this.currentBuffer.length && this.nextBufferReady) {
                [this.currentBuffer, this.nextBuffer] = [this.nextBuffer, this.currentBuffer]
                this.index = 0
                this.nextBufferReady = false
                this.port.postMessage({
                    msg: "process",
                    output: this.nextBuffer,
                }, [this.nextBuffer.buffer])
            }
            return true
        }
    }

    registerProcessor("foo", CustomProcessor)
}

function webWorkerCode() {
    console.log("Web Worker: start")
    let sampleRate
    const freq = 300
    let phase
    let port

    function setup(_sampleRate, _port) {
        console.log("Web Worker: setup")
        sampleRate = _sampleRate
        phase = 0
        port = _port
        port.onmessage = (e) => {
            // console.log("Web Worker <- Audio Worklet:", e.data)
            const length = process(e.data.output)
            port.postMessage({ msg: "process", output: e.data.output, length }, [e.data.output.buffer])
        }
    }

    function process(output) {
        for (let i = 0; i < output.length; i++) {
            output[i] = Math.sin(phase)
            phase += 2*Math.PI*freq/sampleRate
            // Uncomment for to force some underruns (at least in FF):
            for (let j = 0; j < 16384; j++) {}
            phase %= 2*Math.PI
        }
        return output.length
    }

    self.onmessage = async (event) => {
        // Receive sample rate and AudioWorklet's MessagePort from main thread.
        setup(event.data.sampleRate, event.data.port)
    }
}

function getBody(fn) {
    const s = fn.toString()
    return s.slice(s.indexOf("{") + 1, s.lastIndexOf("}"))
}

const webWorker = new Worker(URL.createObjectURL(
    new Blob([getBody(webWorkerCode)], { type: "application/javascript" })
))

webWorker.onmessage = (e) => {
    if (e.data.msg === "process") {
        // console.log(e.data.length, e.data.output)
        swapBuffers(e.data.output)
    }
}

function resumeContextOnInteraction() {
    // from https://github.com/captbaritone/winamp2-js/blob/a5a76f554c369637431fe809d16f3f7e06a21969/js/media/index.js#L8-L27
    if (audioContext.state === "suspended") {
        const resume = async () => {
            await audioContext.resume()
            if (audioContext.state === "running") {
                document.body.removeEventListener("touchend", resume, false)
                document.body.removeEventListener("click", resume, false)
                document.body.removeEventListener("keydown", resume, false)
            }
            setupAudio()
        }
        document.body.addEventListener("touchend", resume, false)
        document.body.addEventListener("click", resume, false)
        document.body.addEventListener("keydown", resume, false)
    } else {
        setupAudio()
    }
}

async function setupAudio() {
    await audioContext.resume()
    console.log("Sample rate:", audioContext.sampleRate)
    await audioContext.audioWorklet.addModule(window.URL.createObjectURL(
        new Blob([getBody(audioWorkletCode)], { type: "application/javascript" })
    ))
    const audioWorklet = new AudioWorkletNode(audioContext, "foo", {
        numberOfInputs: 0,
        numberOfOutputs: 1,
        outputChannelCount: [1],
    })
    webWorker.postMessage({ sampleRate: audioContext.sampleRate, port: audioWorklet.port }, [audioWorklet.port])
    audioWorklet.connect(audioContext.destination)
}
        </script>
    </head>
    <body>
        Hello
        <script type="text/javascript">
resumeContextOnInteraction()
        </script>
    </body>
</html>
